{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pre-processing for the ML for genetic data notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Genotype and phenotype data were downloaded as PLINK files from [Easy GWAS](https://easygwas.ethz.ch/data/public/dataset/view/1/)\n",
    "* Protein-protein interaction data was downloaded from [TAIR](https://www.arabidopsis.org/download/index-auto.jsp?dir=%2Fdownload_files%2FProteins%2FProtein_interaction_data)\n",
    "* Gene positions were downloaded from [TAIR](https://www.arabidopsis.org/download/index-auto.jsp?dir=%2Fdownload_files%2FGenes%2FTAIR9_genome_release%2Ftair9_gff3) \n",
    "\n",
    "The genome build is TAIR9.\n",
    "\n",
    "## Cleaning genotype data\n",
    "* Converted PLINK genotypes to a 0/1 encoding\n",
    "\n",
    "```\n",
    "   plink --file genotype --recode A --out arabidopsis\n",
    "```\n",
    "\n",
    "* Common pre-processing step in Arabidopsis GWAS studies: remove SNPS with a minor allele frequency of less than 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only use SNPs in/near candidate genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214051 ['Chr1_657_T', 'Chr1_3102_G', 'Chr1_4648_A', 'Chr1_4880_T', 'Chr1_5975_G', 'Chr1_6063_T', 'Chr1_6449_C', 'Chr1_6514_C', 'Chr1_6603_C', 'Chr1_6768_G']\n"
     ]
    }
   ],
   "source": [
    "# Names of all SNPs in the data\n",
    "with open('data/athaliana.raw') as f:\n",
    "    header = f.readline()\n",
    "    snp_names = header.split()[6:]\n",
    "    f.close()\n",
    "print(len(snp_names), snp_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 [b'AT1G43700', b'AT3G33520', b'AT1G61040', b'AT2G28290', b'AT5G61150', b'AT5G62430', b'AT3G62090', b'AT1G55080', b'AT4G32980', b'AT3G10390']\n"
     ]
    }
   ],
   "source": [
    "# List of candidate genes\n",
    "import h5py\n",
    "f = h5py.File('data/arabidopsis_processed_data/FT_cand_genes.hd5', 'r')\n",
    "candidate_genes = set(f['gene_id'])\n",
    "print(len(candidate_genes), list(candidate_genes)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate genes positions (not trusting those in the hd5 file to be in the TAIR9 build)\n",
    "chromosomes = {}\n",
    "window = 20000\n",
    "\n",
    "with open('data/TAIR9_GFF3_genes.gff') as f:\n",
    "    for line in f:\n",
    "        ls = line.split()\n",
    "        if ls[2] == 'protein':\n",
    "            if ls[0] in ['ChrC', 'ChrM']:\n",
    "                continue\n",
    "            ccc = int(ls[0][3])\n",
    "            beg = int(ls[3])\n",
    "            end = int(ls[4])\n",
    "            protein_name = ls[8].split(\".\")[0][3:]\n",
    "            if protein_name in candidate_genes:\n",
    "                if not chromosomes.has_key(ccc):\n",
    "                    chromosomes[ccc] = {}\n",
    "                chromosomes[ccc][(beg-window)] = [(end+window), protein_name]\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-77ca477683d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchromosomes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchromosomes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchromosomes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchromosomes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchromosomes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "print(len(chromosomes), len(chromosomes[1]))\n",
    "print(chromosomes[1].keys()[:10])\n",
    "print(chromosomes[1][chromosomes[1].keys()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(chromosomes_ids)? (<ipython-input-8-14b9d4db1b1f>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-14b9d4db1b1f>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    print chromosomes_ids\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(chromosomes_ids)?\n"
     ]
    }
   ],
   "source": [
    "# Sort candidate gene positions (for easier search)\n",
    "sorted_begins = []\n",
    "chromosomes_ids = chromosomes.keys()\n",
    "chromosomes_ids.sort()\n",
    "print(chromosomes_ids)\n",
    "for ccc in chromosomes_ids:\n",
    "    begins = chromosomes[ccc].keys()\n",
    "    begins.sort()\n",
    "    print(ccc, len(begins))\n",
    "    sorted_begins.append(begins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_begins' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-371197f04bdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mccc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mbegins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_begins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mccc\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# list all possible begin positions (those that are before pos)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_begins' is not defined"
     ]
    }
   ],
   "source": [
    "cand_snps = [] # list of indices (in snp_names) of SNPs in/near candidate genes\n",
    "snps_in_genes = {} # key = SNP name, value = [index (in snp_names), set of proteins]\n",
    "snps_by_genes = {} # key = protein name, value = list of SNP names.\n",
    "\n",
    "for snp_idx, snp in enumerate(snp_names):\n",
    "    ccc = int(snp[3])\n",
    "    pos = int(snp.split(\"_\")[1])\n",
    "    begins = sorted_begins[(ccc-1)]\n",
    "    \n",
    "    # list all possible begin positions (those that are before pos)\n",
    "    possible_begs = []\n",
    "    for beg in begins:\n",
    "        if beg <= pos:\n",
    "            possible_begs.append(beg)\n",
    "        else:\n",
    "            break \n",
    "            \n",
    "    proteins = set([])\n",
    "    # reverse the list of possible begin positions\n",
    "    possible_begs.reverse()\n",
    "    for beg in possible_begs:\n",
    "        # look for end positions that are after pos\n",
    "        end, protein_name = chromosomes[ccc][beg]\n",
    "        if end >= pos:\n",
    "            if not snps_in_genes.has_key(snp):\n",
    "                snps_in_genes[snp] = [snp_idx]\n",
    "            proteins.add(protein_name)\n",
    "        else:\n",
    "            # now both begin and end are before pos, stop looking\n",
    "            break\n",
    "                \n",
    "    if snps_in_genes.has_key(snp):\n",
    "        # this SNP is in/near a candidate gene, keep processing\n",
    "        snps_in_genes[snp].append(proteins)\n",
    "        for protein_name in proteins:\n",
    "            if not snps_by_genes.has_key(protein_name):\n",
    "                snps_by_genes[protein_name] = []\n",
    "            snps_by_genes[protein_name].append(snp)\n",
    "                \n",
    "        cand_snps.append(snp_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict_keys' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-99e344ea5e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcand_snps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcand_snps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnps_in_genes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnps_in_genes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnps_in_genes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msnps_in_genes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnps_by_genes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnps_by_genes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnps_by_genes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msnps_by_genes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict_keys' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(len(cand_snps), cand_snps[:10])\n",
    "print(len(snps_in_genes), snps_in_genes.keys()[:10])\n",
    "print(snps_in_genes[snps_in_genes.keys()[0]])\n",
    "print(len(snps_by_genes), snps_by_genes.keys()[:10])\n",
    "print(snps_by_genes[snps_by_genes.keys()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_snps.sort()\n",
    "print(len(set(cand_snps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by minor allele frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count minor allele frequency\n",
    "with open('data/athaliana.raw') as f:\n",
    "    header = f.readline()\n",
    "    snps_ids = header.split()[6:]\n",
    "    snps_freq_dict = {} # key: snp name, value: number of individuals with this SNP's minor allele\n",
    "    num_samples = 0\n",
    "    # initialize snp counts\n",
    "    for idx in cand_snps:\n",
    "        snps_freq_dict[idx] = 0\n",
    "    # count minor alleles\n",
    "    for line in f:\n",
    "        num_samples += 1\n",
    "        ls = line.split()[6:]\n",
    "        for snp_idx in cand_snps:\n",
    "            if int(ls[snp_idx]):\n",
    "                snps_freq_dict[snp_idx] += 1\n",
    "    f.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_samples)\n",
    "print(len(snps_freq_dict), snps_freq_dict.keys()[:10])\n",
    "print(snps_freq_dict[snps_freq_dict.keys()[20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maf threshold = 10%\n",
    "threshold = 0.1 * float(num_samples)\n",
    "\n",
    "keep_snp_names = [] \n",
    "keep_snp_indices = []\n",
    "\n",
    "for snp_idx, snp_id in enumerate(snp_names):\n",
    "    if snps_freq_dict.has_key(snp_idx):\n",
    "        if snps_freq_dict[snp_idx] > threshold:\n",
    "            # keep SNP\n",
    "            keep_snp_names.append(snp_id)\n",
    "            keep_snp_indices.append(snp_idx)\n",
    "            \n",
    "print(len(keep_snp_indices), keep_snp_indices[:10], keep_snp_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/athaliana_small.snps.txt', 'w') as f:\n",
    "    f.write(\"%s\\n\" % \" \".join(keep_snp_names))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "with open('data/athaliana.raw') as f:\n",
    "    f.readline() # header\n",
    "    with open('data/athaliana_small.X.txt', 'w') as g:\n",
    "        for line in f:\n",
    "            samples.append(line.split()[0])\n",
    "            snps = np.array(line.split()[6:])\n",
    "            # only keep SNPs with index in keep_snp_indices\n",
    "            # and convert \"2\" into \"1\"\n",
    "            g.write(\"%s\\n\" % str.replace(\" \".join(snps[keep_snp_indices]), '2', '1'))\n",
    "    f.close()\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/athaliana.samples.txt', 'w') as g:\n",
    "    g.write(\" \".join(samples))\n",
    "    g.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9419 ['Chr1_21043_T', 'Chr1_21128_T', 'Chr1_21829_C', 'Chr1_22522_G', 'Chr1_27265_C', 'Chr1_29291_A', 'Chr1_31515_G', 'Chr1_32807_A', 'Chr1_35856_C', 'Chr1_37072_G']\n"
     ]
    }
   ],
   "source": [
    "with open('data/athaliana_small.snps.txt') as f:\n",
    "    snp_names = f.readline().split()\n",
    "    f.close()\n",
    "print(len(snp_names), snp_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1307 [9381, 9380, 9378, 9371, 9367, 9363, 9356, 9355, 9354, 9353]\n"
     ]
    }
   ],
   "source": [
    "samples = list(np.loadtxt('data/athaliana.samples.txt', # file names\n",
    "                         dtype=int)) # values are integers\n",
    "print(len(samples), samples[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the design matrix \n",
    "X = np.loadtxt('data/athaliana_small.X.txt',  # file names\n",
    "               dtype='int') # values are integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p = X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "* Create a sparse matrix.\n",
    "* Create edges between all neighboring SNPs (in the genetic sequence), with a weight of 0.01.\n",
    "* Create edges between all pairs of SNPs that are in the same gene.\n",
    "* Create edges between all pairs of SNPs that are in two interacting genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = len(keep_snp_indices)\n",
    "print(p)\n",
    "W = sparse.lil_matrix(sparse.eye(p, k=1)*0.01) # connect each SNP to the next one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SNP index in X from its name\n",
    "snp_index = {}\n",
    "for snp_idx, snp_name in enumerate(keep_snp_names):\n",
    "    snp_index[snp_name] = snp_idx\n",
    "print(len(snp_index), snp_index.keys()[:10], snp_index[snp_index.keys()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gene membership\n",
    "for snp_list in snps_by_genes.values():\n",
    "    if not len(snp_list):\n",
    "        break\n",
    "    for ix1, snp1 in enumerate(snp_list):\n",
    "        if snp_index.has_key(snp1):\n",
    "            # We kept that SNP\n",
    "            for snp2 in snp_list[ix1+1:]:\n",
    "                if snp_index.has_key(snp2):\n",
    "                    W[snp_index[snp1], snp_index[snp2]] = 1.\n",
    "                    W[snp_index[snp2], snp_index[snp1]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protein-protein interactions\n",
    "ppi_set = set([])\n",
    "with open('data/TairProteinInteraction.20090527.txt') as f:\n",
    "    f.readline() # header\n",
    "    for line in f:\n",
    "        ls = line.split()\n",
    "        if ls[0] < ls[2]:\n",
    "            ppi = (ls[0], ls[2])\n",
    "        else:\n",
    "            ppi = (ls[2], ls[0])\n",
    "        ppi_set.add(ppi)\n",
    "print(len(ppi_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ppi in ppi_set:\n",
    "    if snps_by_genes.has_key(ppi[0]):\n",
    "        for snp1 in snps_by_genes[ppi[0]]:        \n",
    "            if snp_index.has_key(snp1):\n",
    "                if snps_by_genes.has_key(ppi[1]):\n",
    "                    for snp2 in snps_by_genes[ppi[1]]:\n",
    "                        if snp_index.has_key(snp2):\n",
    "                            W[snp_index[snp1], snp_index[snp2]] = 1.\n",
    "                            W[snp_index[snp2], snp_index[snp1]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1291643./(9419*9419)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = sparse.coo_matrix(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([W.row, W.col, W.data])\n",
    "np.savetxt('data/athaliana_small.W.txt', A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_saved = np.loadtxt('data/athaliana_small.W.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = sparse.coo_matrix((w_saved[2, :], (np.array(w_saved[0, :], dtype=int), \n",
    "                                       np.array(w_saved[1, :], dtype=int))), shape=(p, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check incidence matrix can be built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute node degrees \n",
    "degrees = np.zeros((p, ))\n",
    "for vertex in W.row:\n",
    "    degrees[vertex] += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tim = sparse.lil_matrix((W.row.shape[0], p))\n",
    "for ix, edge in enumerate(W.data):\n",
    "    tim[ix, W.row[ix]] = np.sqrt(edge / degrees[W.row[ix]])\n",
    "    tim[ix, W.col[ix]] = - np.sqrt(edge / degrees[W.col[ix]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check ncLasso runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del W, degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO CHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 samples have a phenotype\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/old/athaliana.2W.pheno', # file name\n",
    "                 header=None, # columns have no header\n",
    "                 delim_whitespace=True) # columns are separated by white space\n",
    "\n",
    "# Create vector of sample IDs\n",
    "samples_with_phenotype = list(df[0])\n",
    "print(len(samples_with_phenotype), \"samples have a phenotype\")\n",
    "\n",
    "# Create vector of phenotypes\n",
    "y_2W = np.array(df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 [5837, 6008, 6009, 6016, 6040, 6042, 6043, 6064, 6074, 6243]\n"
     ]
    }
   ],
   "source": [
    "print(len(samples_with_phenotype), samples_with_phenotype[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 9419\n"
     ]
    }
   ],
   "source": [
    "# Restrict X to the samples with a 2W phenotype, in correct order\n",
    "# X_2W[i] = X[samples.index(samples_with_phenotype[i])]\n",
    "X_2W = X[np.array([samples.index(sample_id) \\\n",
    "                   for sample_id in samples_with_phenotype]), :]\n",
    "n, p = X_2W.shape\n",
    "print(n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can delete X now to free space\n",
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import base, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ncLasso(base.BaseEstimator, base.RegressorMixin):\n",
    "    def __init__(self, transposed_incidence=None, lambda1=1.0, lambda2=1.0):\n",
    "        self.transposed_incidence = transposed_incidence # sparse matrix\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        \n",
    "        alpha = self.lambda1/(np.sqrt(self.lambda2+1.))\n",
    "        self.lasso = linear_model.Lasso(fit_intercept=True, alpha=alpha)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        print(self.lambda1)\n",
    "        print(self.lambda2)\n",
    "        \n",
    "        y_new = np.hstack((y, np.zeros((self.transposed_incidence.shape[0], ))))\n",
    "        print(y_new.shape, X.shape)\n",
    "        X_new = 1/(np.sqrt(self.lambda2+1)) * sparse.vstack((X, np.sqrt(self.lambda2)*\\\n",
    "                                                    self.transposed_incidence))\n",
    "        \n",
    "        \n",
    "        self.lasso.fit(X_new, y_new)\n",
    "        self.coef_ = self.lasso.coef_[:X.shape[1]]/(np.sqrt(self.lambda2+1))\n",
    "        \n",
    "        \n",
    "    def predict(self, X, y=None):\n",
    "        return self.lasso.predict(X)\n",
    "    \n",
    "    \n",
    "    def score(self, X, y=None):\n",
    "        return self.lasso.score(X, y)                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [0.001]# np.logspace(-3., 2., num=6)\n",
    "l2 = [0.1] #np.logspace(0., 2., num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncLasso(lambda1=1.0, lambda2=1.0,\n",
      "    transposed_incidence=<1291643x9419 sparse matrix of type '<type 'numpy.float64'>'\n",
      "\twith 2582679 stored elements in LInked List format>)\n"
     ]
    }
   ],
   "source": [
    "nclasso = ncLasso(transposed_incidence=tim)\n",
    "print nclasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "0.1\n",
      "(1291744,) (101, 9419)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "predict() takes exactly 2 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-b07fa43b0ce5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m                                                              'lambda2': l2}, \n\u001b[0;32m      3\u001b[0m                                         scoring='explained_variance')\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel_nc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_2W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_2W\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \"\"\"\n\u001b[0;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_multimetric_score\u001b[1;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/scorer.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m     99\u001b[0m         super(_PredictScorer, self).__call__(estimator, X, y_true,\n\u001b[0;32m    100\u001b[0m                                              sample_weight=sample_weight)\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n",
      "\u001b[1;32m<ipython-input-18-a9f834ebc240>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlasso\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: predict() takes exactly 2 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "model_nc = model_selection.GridSearchCV(nclasso, param_grid={'lambda1': l1, \n",
    "                                                             'lambda2': l2}, \n",
    "                                        scoring='explained_variance')\n",
    "model_nc.fit(X_2W, y_2W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 9419)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(range(p), # x = SNP position\n",
    "            model_nc.coef_)  # y = regression weights\n",
    "\n",
    "plt.xlabel(\"SNP\")\n",
    "plt.ylabel(\"lasso regression weight\")\n",
    "plt.xlim([0, p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(\"hello\")? (<ipython-input-1-2a0eaa89f43f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-2a0eaa89f43f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print \"hello\"\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"hello\")?\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count minor allele frequency\n",
    "with open('data/athaliana.raw') as f:\n",
    "    header = f.readline()\n",
    "    snps_ids = header.split(\" \")[6:]\n",
    "    snps_freq_dict = {} # key: snp name, value: number of individuals with this SNP's minor allele\n",
    "    num_samples = 0\n",
    "    for idx in range(len(snps_ids)):\n",
    "        snps_freq_dict[idx] = 0\n",
    "    for line in f:\n",
    "        num_samples += 1\n",
    "        for idx, snp in enumerate(line.split(\" \")[6:]):\n",
    "            if int(snp):\n",
    "                snps_freq_dict[idx] += 1\n",
    "    f.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maf threshold = 10%\n",
    "threshold = 0.1 * float(num_samples)\n",
    "    \n",
    "new_header = []\n",
    "snps_pass_maf_idx = []\n",
    "for idx in range(len(snps_ids)):\n",
    "    if snps_freq_dict[idx] > threshold:\n",
    "        # keep SNP\n",
    "        new_header.append(snps_ids[idx])\n",
    "        snps_pass_maf_idx.append(idx)\n",
    "        \n",
    "print(len(new_header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/athaliana.snps.txt', 'w') as g:\n",
    "    g.write(\" \".join(new_header))\n",
    "    g.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "* Map SNPS to genes using a 20kbp window.\n",
    "* For the purpose of this lab, we want to be able to run all methods quickly. We selected 20 000 SNPs at random among those that are mapped to genes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/athaliana.snps.txt') as f:\n",
    "    snps_pass_maf = f.readline().split()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(snps_pass_maf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromosomes = {}\n",
    "window = 20000\n",
    "with open('data/TAIR9_GFF3_genes.gff') as f:\n",
    "    for line in f:\n",
    "        ls = line.split()\n",
    "        if ls[2] == 'protein':\n",
    "            if ls[0] in ['ChrC', 'ChrM']:\n",
    "                continue\n",
    "            ccc = int(ls[0][3])\n",
    "            beg = int(ls[3])\n",
    "            end = int(ls[4])\n",
    "            protein_name = ls[8].split(\".\")[0][3:]\n",
    "            if not chromosomes.has_key(ccc):\n",
    "                chromosomes[ccc] = {}\n",
    "            chromosomes[ccc][(beg-window)] = [(end+window), protein_name]\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_begins = []\n",
    "chromosomes_ids = chromosomes.keys()\n",
    "chromosomes_ids.sort()\n",
    "print(chromosomes_ids)\n",
    "for ccc in chromosomes_ids:\n",
    "    begins = chromosomes[ccc].keys()\n",
    "    begins.sort()\n",
    "    print ccc, len(begins)\n",
    "    sorted_begins.append(begins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File('data/arabidopsis_processed_data/FT_cand_genes.hd5', 'r')\n",
    "candidate_genes = set(f['gene_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_snps = [] # list of indices (in snps_pass_maf) of candidate SNPs\n",
    "gene_snps = [] # list of indices (in snps_pass_maf) of SNPs in/near genes\n",
    "snps_in_genes = {} # key = SNP name, value = [index (in snps_pass_maf), set of proteins]\n",
    "snps_by_genes = {} # key = protein name, value = list of SNP names.\n",
    "\n",
    "\n",
    "for idx_in_snps_pass_maf, snp in enumerate(snps_pass_maf):\n",
    "    ccc = int(snp[3])\n",
    "    pos = int(snp.split(\"_\")[1])\n",
    "    begins = sorted_begins[(ccc-1)]\n",
    "    \n",
    "    # list all possible begin positions (those that are before pos)\n",
    "    possible_begs = []\n",
    "    for beg in begins:\n",
    "        if beg <= pos:\n",
    "            possible_begs.append(beg)\n",
    "        else:\n",
    "            break \n",
    "            \n",
    "    proteins = set([])\n",
    "    # reverse the list of possible begin positions\n",
    "    possible_begs.reverse()\n",
    "    for beg in possible_begs:\n",
    "        # look for end positions that are after pos\n",
    "        end, protein_name = chromosomes[ccc][beg]\n",
    "        if end >= pos:\n",
    "            if not snps_in_genes.has_key(snp):\n",
    "                snps_in_genes[snp] = [idx_in_snps_pass_maf]\n",
    "            proteins.add(protein_name)\n",
    "        else:\n",
    "            # now both begin and end are before pos, stop looking\n",
    "            break\n",
    "                \n",
    "    if snps_in_genes.has_key(snp):\n",
    "        # this is not an intergenic gene, keep processing\n",
    "        snps_in_genes[snp].append(proteins)\n",
    "        for protein_name in proteins:\n",
    "            if not snps_by_genes.has_key(protein_name):\n",
    "                snps_by_genes[protein_name] = []\n",
    "            snps_by_genes[protein_name].append(snp)\n",
    "                \n",
    "        if len(proteins.intersection(candidate_genes)):\n",
    "            cand_snps.append(idx_in_snps_pass_maf)\n",
    "        else:\n",
    "            gene_snps.append(idx_in_snps_pass_maf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cand_snps), len(gene_snps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(snps_pass_maf[:10], len(snps_pass_maf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices in snps_pass_maf of the SNPs that we are keeping\n",
    "now_keeping = [idx for idx in cand_snps]\n",
    "import random\n",
    "random.shuffle(gene_snps)\n",
    "now_keeping.extend(gene_snps[:10000])\n",
    "now_keeping.sort()\n",
    "\n",
    "# indices in the original SNP list of the SNPs that we are keeping\n",
    "with open('data/athaliana.raw') as f:\n",
    "    all_snps = f.readline().split()[6:]\n",
    "    f.close()\n",
    "    \n",
    "now_keeping_indices = []\n",
    "for idx in now_keeping:\n",
    "    now_keeping_indices.append(all_snps.index(snps_pass_maf[idx]))\n",
    "    \n",
    "now_keeping_indices.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now_keeping_indices.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/athaliana_small.snps.txt', 'w') as f:\n",
    "    f.write(\"%s\\n\" % \" \".join([all_snps[idx] for idx in now_keeping_indices]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "with open('data/athaliana.raw') as f:\n",
    "    f.readline() # header\n",
    "    with open('data/athaliana_small.X.txt', 'w') as g:\n",
    "        for line in f:\n",
    "            samples.append(line.split()[0])\n",
    "            snps = np.array(line.split()[6:])\n",
    "            g.write(\"%s\\n\" % str.replace(\" \".join(snps[now_keeping_indices]), '2', '1'))\n",
    "    f.close()\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/athaliana.samples.txt', 'w') as g:\n",
    "    g.write(\" \".join(samples))\n",
    "    g.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning phenotype data\n",
    "* For each of the phenotypes, regress out the 4 first principal components of the genetic data. This is a common pre-processing step to remove population structure effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For 2W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need the index in X, that is to say in samples, of the samples in 2W.pheno\n",
    "rows_2W = []\n",
    "y = []\n",
    "samples_2W = []\n",
    "with open('data/2W.pheno') as f:\n",
    "    f.readline() # header\n",
    "    for line in f:\n",
    "        sample_id = line.split()[1]\n",
    "        rows_2W.append(samples.index(sample_id))\n",
    "        y.append(float(line.split()[2]))\n",
    "    f.close()\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt('data/athaliana_small.X.txt', dtype='int')\n",
    "X = X[rows_2W, :]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check genomic inflation -- is there population structure?\n",
    "\n",
    "We compute p-values for the phenotype and check whether the distribution matches a uniform distribution. If not, it is likely due to confounding by population structure. We regress out PCs of the genotype data until the distribution is uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = []\n",
    "for feat_idx in range(X.shape[1]):\n",
    "    myX = X[:, feat_idx]\n",
    "    myX = sm.add_constant(myX)\n",
    "    est = sm.regression.linear_model.OLS(y, myX)\n",
    "    est2 = est.fit()\n",
    "    pvalues.append(est2.pvalues[1])\n",
    "pvalues = np.array(pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ plot\n",
    "import scipy.stats as ss\n",
    "ss.probplot(pvalues, dist=\"uniform\", plot=plt)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regress out principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=4)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proj = X.dot(pca.components_.T)\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_proj, y)\n",
    "y_pred = model.predict(X_proj)\n",
    "y_res = y - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = []\n",
    "for feat_idx in range(X.shape[1]):\n",
    "    myX = X[:, feat_idx]\n",
    "    myX = sm.add_constant(myX)\n",
    "    est = sm.regression.linear_model.OLS(y_res, myX)\n",
    "    est2 = est.fit()\n",
    "    pvalues.append(est2.pvalues[1])\n",
    "pvalues = np.array(pvalues)\n",
    "\n",
    "# QQ plot\n",
    "import scipy.stats as ss\n",
    "ss.probplot(pvalues, dist=\"uniform\", plot=plt)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/athaliana.2W.pheno', 'w') as f:\n",
    "    for ix, sample_id in enumerate([samples[ixx] for ixx in rows_2W]):\n",
    "        f.write('%s %.2f\\n' % (sample_id, y_res[ix]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For 4W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need the index in X, that is to say in samples, of the samples in 2W.pheno\n",
    "rows_4W = []\n",
    "y = []\n",
    "samples_4W = []\n",
    "with open('data/4W.pheno') as f:\n",
    "    f.readline() # header\n",
    "    for line in f:\n",
    "        sample_id = line.split()[1]\n",
    "        rows_4W.append(samples.index(sample_id))\n",
    "        y.append(float(line.split()[2]))\n",
    "    f.close()\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt('data/athaliana_small.X.txt', dtype='int')\n",
    "X = X[rows_4W, :]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = []\n",
    "for feat_idx in range(X.shape[1]):\n",
    "    myX = X[:, feat_idx]\n",
    "    myX = sm.add_constant(myX)\n",
    "    est = sm.regression.linear_model.OLS(y, myX)\n",
    "    est2 = est.fit()\n",
    "    pvalues.append(est2.pvalues[1])\n",
    "pvalues = np.array(pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ plot\n",
    "import scipy.stats as ss\n",
    "ss.probplot(pvalues, dist=\"uniform\", plot=plt)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regress out principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=4)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proj = X.dot(pca.components_.T)\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_proj, y)\n",
    "y_pred = model.predict(X_proj)\n",
    "y_res = y - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = []\n",
    "for feat_idx in range(X.shape[1]):\n",
    "    myX = X[:, feat_idx]\n",
    "    myX = sm.add_constant(myX)\n",
    "    est = sm.regression.linear_model.OLS(y_res, myX)\n",
    "    est2 = est.fit()\n",
    "    pvalues.append(est2.pvalues[1])\n",
    "pvalues = np.array(pvalues)\n",
    "\n",
    "# QQ plot\n",
    "import scipy.stats as ss\n",
    "ss.probplot(pvalues, dist=\"uniform\", plot=plt)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/athaliana.4W.pheno', 'w') as f:\n",
    "    for ix, sample_id in enumerate([samples[ixx] for ixx in rows_4W]):\n",
    "        f.write('%s %.2f\\n' % (sample_id, y_res[ix]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the network\n",
    "* Create a sparse matrix.\n",
    "* Create edges between all neighboring SNPs (in the genetic sequence), with a weight of 0.01.\n",
    "* Create edges between all pairs of SNPs that are in the same gene.\n",
    "* Create edges between all pairs of SNPs that are in two interacting genes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index of SNPs names in X\n",
    "snp_index = {} # snp_name: snp_index\n",
    "with open('data/athaliana_small.snps.txt') as f:\n",
    "    snps = f.readline().split()\n",
    "    f.close()\n",
    "\n",
    "for snp_ix, snp_name in enumerate(snps):\n",
    "    snp_index[snp_name] = snp_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = len(snps)\n",
    "print(p)\n",
    "W = sparse.lil_matrix(sparse.eye(p, k=1)*0.01) # connect each SNP to the next one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gene membership\n",
    "for snp_list in snps_by_genes.values():\n",
    "    if len(snp_list) <= 1:\n",
    "        break\n",
    "    for ix1, snp1 in enumerate(snp_list):\n",
    "        if snp_index.has_key(snp1):\n",
    "            # We kept that SNP\n",
    "            for snp2 in snp_list[ix1+1:]:\n",
    "                if snp_index.has_key(snp2):\n",
    "                    W[snp_index[snp1], snp_index[snp2]] = 1.\n",
    "                    W[snp_index[snp2], snp_index[snp1]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protein-protein interactions\n",
    "ppi_set = set([])\n",
    "with open('data/TairProteinInteraction.20090527.txt') as f:\n",
    "    f.readline() # header\n",
    "    for line in f:\n",
    "        ls = line.split()\n",
    "        if ls[0] < ls[2]:\n",
    "            ppi = (ls[0], ls[2])\n",
    "        else:\n",
    "            ppi = (ls[2], ls[0])\n",
    "        ppi_set.add(ppi)\n",
    "print(len(ppi_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ppi in ppi_set:\n",
    "    if snps_by_genes.has_key(ppi[0]):\n",
    "        for snp1 in snps_by_genes[ppi[0]]:        \n",
    "            if snp_index.has_key(snp1):\n",
    "                if snps_by_genes.has_key(ppi[1]):\n",
    "                    for snp2 in snps_by_genes[ppi[1]]:\n",
    "                        if snp_index.has_key(snp2):\n",
    "                            W[snp_index[snp1], snp_index[snp2]] = 1.\n",
    "                            W[snp_index[snp2], snp_index[snp1]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1087562./(19419*19419)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = sparse.coo_matrix(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([W.row, W.col, W.data])\n",
    "np.savetxt('data/athaliana_small.W.txt', A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "www_ = np.loadtxt('data/athaliana_small.W.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = sparse.coo_matrix((www_[2], (www_[0], www_[1])), shape=(p, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-create SNP by gene list to save as file\n",
    "Restricted to the SNPs included in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SNP names\n",
    "with open('data/athaliana_small.snps.txt') as f:\n",
    "    snp_names = f.readline().split()\n",
    "    f.close()\n",
    "print(len(snp_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromosomes = {}\n",
    "window = 20000\n",
    "with open('data/TAIR9_GFF3_genes.gff') as f:\n",
    "    for line in f:\n",
    "        ls = line.split()\n",
    "        if ls[2] == 'protein':\n",
    "            if ls[0] in ['ChrC', 'ChrM']:\n",
    "                continue\n",
    "            ccc = int(ls[0][3])\n",
    "            beg = int(ls[3])\n",
    "            end = int(ls[4])\n",
    "            protein_name = ls[8].split(\".\")[0][3:]\n",
    "            if not chromosomes.has_key(ccc):\n",
    "                chromosomes[ccc] = {}\n",
    "            chromosomes[ccc][(beg-window)] = [(end+window), protein_name]\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_begins = []\n",
    "chromosomes_ids = chromosomes.keys()\n",
    "chromosomes_ids.sort()\n",
    "print chromosomes_ids\n",
    "for ccc in chromosomes_ids:\n",
    "    begins = chromosomes[ccc].keys()\n",
    "    begins.sort()\n",
    "    print ccc, len(begins)\n",
    "    sorted_begins.append(begins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_snps = [] # list of indices (in snps_pass_maf) of candidate SNPs\n",
    "gene_snps = [] # list of indices (in snps_pass_maf) of SNPs in/near genes\n",
    "snps_in_genes = {} # key = SNP name, value = [index (in snps_pass_maf), set of proteins]\n",
    "snps_by_genes = {} # key = protein name, value = list of SNP names.\n",
    "\n",
    "for snp_idx, snp in enumerate(snp_names):\n",
    "    ccc = int(snp[3])\n",
    "    pos = int(snp.split(\"_\")[1])\n",
    "    begins = sorted_begins[(ccc-1)]\n",
    "    \n",
    "    # list all possible begin positions (those that are before pos)\n",
    "    possible_begs = []\n",
    "    for beg in begins:\n",
    "        if beg <= pos:\n",
    "            possible_begs.append(beg)\n",
    "        else:\n",
    "            break \n",
    "            \n",
    "    proteins = set([])\n",
    "    # reverse the list of possible begin positions\n",
    "    possible_begs.reverse()\n",
    "    for beg in possible_begs:\n",
    "        # look for end positions that are after pos\n",
    "        end, protein_name = chromosomes[ccc][beg]\n",
    "        if end >= pos:\n",
    "            if not snps_in_genes.has_key(snp):\n",
    "                snps_in_genes[snp] = [snp_idx]\n",
    "            proteins.add(protein_name)\n",
    "        else:\n",
    "            # now both begin and end are before pos, stop looking\n",
    "            break\n",
    "                \n",
    "    if snps_in_genes.has_key(snp):\n",
    "        # this is not an intergenic gene, keep processing\n",
    "        snps_in_genes[snp].append(proteins)\n",
    "        for protein_name in proteins:\n",
    "            if not snps_by_genes.has_key(protein_name):\n",
    "                snps_by_genes[protein_name] = []\n",
    "            snps_by_genes[protein_name].append(snp)\n",
    "                \n",
    "        if len(proteins.intersection(candidate_genes)):\n",
    "            cand_snps.append(snp_idx)\n",
    "        else:\n",
    "            gene_snps.append(snp_idx)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/athaliana.snps_by_gene.txt', 'w') as f:\n",
    "    for gene, snps_list in snps_by_genes.iteritems():\n",
    "        f.write(\"%s %s\\n\" % (gene, \" \".join(snps_list)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of candidate genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File('data/arabidopsis_processed_data/FT_cand_genes.hd5', 'r')\n",
    "candidate_genes = list(f['gene_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/athaliana.candidates.txt', 'w') as f:\n",
    "    f.write(\"%s\\n\" % \" \".join(candidate_genes))\n",
    "    f.close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
