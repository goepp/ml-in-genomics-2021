{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning for genetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The goal of this practical session is to manipulate high-dimensional, low sample-size data that is typical of many genetic applications.\n",
    "\n",
    "Here we will work with GWAS data from _Arabidopsis thaliana_, which is a plant model organism (https://upload.wikimedia.org/wikipedia/commons/6/6f/Arabidopsis_thaliana.jpg).\n",
    "\n",
    "The genotypes are hence described by **Single Nucleotide Polymorphisms, or SNPs**. Our goal will be to use this data to identify regions of the genome that can be linked with various growth and flowering traits (**phenotypes**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline \n",
    "# imports matplotlib as plt and numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', **{'size': 16}) # font size for text on plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description\n",
    "\n",
    "* `data/athaliana_small.X.txt` is the design matrix. As many rows as samples, as many columns as SNPs\n",
    "* the SNPs are given (in order) in `data/athaliana_small.snps.txt`. \n",
    "* the samples are given (in order) in `data/athaliana.samples.txt`.\n",
    "\n",
    "* the transformed phenotypes are given in `data/athaliana.4W.pheno` and `data/athaliana.2W.pheno`. The first column is the sample's ID, and the second the phenotype.\n",
    "\n",
    "* `data/athaliana.candidates.txt` contains a list of _A. thaliana_ genes known or strongly suspected to be associated with flowering times.\n",
    "\n",
    "* the feature network is in `data/athaliana_small.W.txt`. It has been saved as 3 arrays, corresponding to the row, col, and data attributes of a [scipy.sparse coo_matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "We will start by working without the feature network, on the 2W phenotype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SNP names\n",
    "with open('data/athaliana_small.snps.txt') as f:\n",
    "    snp_names = f.readline().split()\n",
    "    f.close()\n",
    "print(len(snp_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the design matrix -- this can take time!\n",
    "X = np.loadtxt('data/athaliana_small.X.txt',  # file names\n",
    "               dtype = 'int') # values are integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: How many samples are there in the data? How many SNPs are there?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1307 samples and 9 419 SNPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the sample names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list(np.loadtxt('data/athaliana.samples.txt', # file names\n",
    "                         dtype = int)) # values are integers\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the 2W phenotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/athaliana.2W.pheno', # file name\n",
    "                 header = None, # columns have no header\n",
    "                 delim_whitespace = True) # columns are separated by white space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2W phenotype is not available for all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector of sample IDs\n",
    "samples_with_phenotype = list(df[0])\n",
    "print(len(samples_with_phenotype), \"samples have a phenotype\")\n",
    "\n",
    "# Create vector of phenotypes\n",
    "y_2W = np.array(df[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to restrict X to the samples with a 2W phenotype, in correct order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2W = X[np.array([samples.index(sample_id) \\\n",
    "                   for sample_id in samples_with_phenotype]), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: How many samples do we have now? And how many SNPs? Does this make the task of biomarker detection simpler or harder?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_2W.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ There are the same number of features but (way) fewer samples: the statistical power has decreased! And so the task of detecting explanatory SNPs is harder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can delete X now if you want, to free space\n",
    "del X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the list of candidate genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/athaliana.candidates.txt') as f:\n",
    "    candidate_genes = f.readline().split()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the snps to gene mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_by_snp = {} # key: SNP, value = [genes in/near which this SNP is]\n",
    "with open('data/athaliana.snps_by_gene.txt') as f:\n",
    "    for line in f:\n",
    "        ls = line.split()\n",
    "        gene_id = ls[0]\n",
    "        for snp_id in ls[1:]:\n",
    "            if not snp_id in genes_by_snp:\n",
    "                genes_by_snp[snp_id] = []\n",
    "            genes_by_snp[snp_id].append(gene_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data in a train and test set\n",
    "\n",
    "In machine learning, we always split the data into a *train* set, which serves to fit the model, and a *test* set, which serves to measure the model's performance.\n",
    "\n",
    "__Q: Do you remember why? What happens if we do both the training and testing on the same data?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ Evaluating a model on the same data used to fit the model favors model that overfit the data at hand, and these models have poor generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set aside a test set, containing 20% of our samples, on which to evaluate the quality of our predictive models.\n",
    "\n",
    "__Q: What problem occurs if we set a test set that is too large in proportion? What problem occurs when it is set too small?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ If the proportion of samples in the test set is too large, the training set becomes too small to be able to fit the model correctly. If it is too small, the measure of performance of the model will be prone to too much variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2W_tr, X_2W_te, y_2W_tr, y_2W_te = \\\n",
    "    model_selection.train_test_split(X_2W, y_2W, test_size = 0.2, random_state = 17)\n",
    "print(X_2W_tr.shape, X_2W_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.hist(y_2W_tr, bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the genotype's correlation structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "sigma = pd.DataFrame(X_2W_tr).corr()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(sigma.iloc[0:1000, 0:1000])\n",
    "ax[1].imshow(sigma.iloc[72:120, 72:120])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: What observation can you make about the phenotype and genotype?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ The phenotype has an unimodal distribution (only one peak), but with a few outlying values.\n",
    "\n",
    "The genotype has a correlation structure which displays \"blocks\" of high correlation, called *Linkage Disequilibrium* (LD) blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-test\n",
    "\n",
    "Let us start by running a statistical test for association of each SNP feature with the phenotype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-test on a single SNP\n",
    "We will perform a linear regression on a single SNP and test whether this SNP has an effect on the phenotype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = sm.regression.linear_model.OLS(y_2W_tr, sm.add_constant(X_2W_tr[:, 0])).fit()\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: In the previous table, where is the p-value of the T-test? What can you conclude about the effect of the first SNP on the phenotype?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ The p-value is 0.310: we cannot reject $\\mathcal{H}_0$, and so the first SNP is estimated to have no effect on the phenotype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.regplot(x = 'x', y = 'y', data = pd.DataFrame({'x': X_2W_tr[:, 0], 'y': y_2W_tr})).set(xlim = (-0.1, 1.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-test on all SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = []\n",
    "for snp_idx in range(p):\n",
    "    # only look a the column corresponding at that SNP\n",
    "    X_snp = X_2W_tr[:, snp_idx]\n",
    "    # run a linear regression (with bias) between the phenotype and this SNP\n",
    "    X_snp = sm.add_constant(X_snp)\n",
    "    est = sm.regression.linear_model.OLS(y_2W_tr, X_snp)\n",
    "    est2 = est.fit()\n",
    "    # get the p-value from the model \n",
    "    pvalues.append(est2.pvalues[1])\n",
    "pvalues = np.array(pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan plot\n",
    "\n",
    "The common way to visualize such results is by using a Manhattan plot: we will plot all SNPs on the x-axis, and on the y-axis we'll have the opposite of the log base 10 of the p-value. The lower the p-value, the higher the corresponding marker. \n",
    "\n",
    "We will also add a horizontal line that corresponds to the _threshold for significance_. Because we are testing multiple hypotheses, we need to lower our threshold accordingly. We will use __Bonferroni correction__ and divide the significance threshold (say, alpha=0.05) by the number of tests, that is, the number of SNPs p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(p), # x = SNP position\n",
    "            -np.log10(pvalues)) # y = -log10 p-value \n",
    "\n",
    "# significance threshold according to Bonferroni correction\n",
    "t = -np.log10(0.05 / p)\n",
    "plt.plot([0, p], [t, t])\n",
    "\n",
    "# plot labels\n",
    "plt.xlabel(\"feature\")\n",
    "plt.ylabel(\"-log10 p-value\")\n",
    "plt.xlim([0, p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: What do you observe? Are any SNPs significantly associated with the phenotype? \n",
    "Use data/athaliana.snps_by_gene.txt and data/athaliana.candidates.txt to check whether this matches a priori information.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n",
    "thresh = 0.05 / p # significance threshold set using the Bonferroni correction\n",
    "\n",
    "for snp_idx in np.where(pvalues < thresh)[0]:\n",
    "    print((\"%.2e\" % pvalues[snp_idx]), snp_names[snp_idx])\n",
    "    for gene_id in genes_by_snp[snp_names[snp_idx]]:\n",
    "        if gene_id in candidate_genes:\n",
    "            print(\"\\t in/near candidate gene %s\" % gene_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ Chr5_3185806_C is just at significance threshold with a p-value of 2x10^-6. It is in or near gene [AT5G10140](https://www.arabidopsis.org/servlets/TairObject?accession=locus:2184118), which is known to play a role in flowering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = linear_model.LinearRegression(fit_intercept = True)\n",
    "model_lr.fit(X_2W_tr, y_2W_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 5))\n",
    "plt.scatter(range(p), # x = SNP position\n",
    "            model_lr.coef_, # y = regression weights\n",
    "            s = 10)  # point size\n",
    "\n",
    "plt.xlabel(\"SNP\")\n",
    "plt.ylabel(\"regression weight\")\n",
    "plt.xlim([0, p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: What do you observe? How can you interpret these results? Do any of the SNPs strike you as having a strong influence on the phenotype?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ The following SNPs are the ones with the ten highest weights (in absolute value). They are all near candidate genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_weights = np.abs(model_lr.coef_)\n",
    "highest_weights.sort()\n",
    "highest_weights = highest_weights[-10:]\n",
    "\n",
    "for w in highest_weights:\n",
    "    for snp_idx in np.where(model_lr.coef_ == w)[0]:\n",
    "        print(w, snp_names[snp_idx])\n",
    "        for gene_id in genes_by_snp[snp_names[snp_idx]]:\n",
    "            if gene_id in candidate_genes:\n",
    "                print(\"\\t in/near candidate gene %s\" % gene_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model predictive power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we measure the performance of our model on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now look at the predictive power of the lasso estimated model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: What is the definition of the variance explained? You may use the [scikit learn documentation](https://sklearn.org/modules/classes.html#sklearn-metrics-metrics). What values can this metric take? and to what cases do the extreme values correspond to?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ The explained variance is $1 - \\frac{\\text{variance of the residuals}}{\\text{variance of the output}}$. It is equal to one in the case of a perfect fit (the residuals are all equal to zero, which can only happen with overfitting, and is therefore not desirable). A higher value means the genotype explains a large portion of the variability of the phenotype, which is good. It can be negative (in case of arbitrarily poor fits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2W_lr_pred = model_lr.predict(X_2W_te)\n",
    "\n",
    "print(\"Percentage of variance explained (using all SNPs): %.2f\" % \\\n",
    "    metrics.explained_variance_score(y_2W_te, y_2W_lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5, 5))\n",
    "plt.scatter(y_2W_te, y_2W_lr_pred)\n",
    "\n",
    "plt.xlabel(\"true phenotype\")\n",
    "plt.ylabel(\"prediction\")\n",
    "plt.xlim([np.min(y_2W_te) - 5, np.max(y_2W_te) + 5])\n",
    "plt.ylim([np.min(y_2W_te) - 5, np.max(y_2W_te) + 5])\n",
    "plt.axline(xy1 = [0, 0], slope = 1, c = \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso(fit_intercept = True, max_iter = 6000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define cross-validation grid search and learn lasso with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-4., 1., num = 20)\n",
    "model_l1 = model_selection.GridSearchCV(lasso, param_grid = {'alpha': alphas}, \n",
    "                                        scoring = 'explained_variance')\n",
    "model_l1.fit(X_2W_tr, y_2W_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 4))\n",
    "plt.scatter(range(p), # x = SNP position\n",
    "            model_l1.best_estimator_.coef_)  # y = regression weights\n",
    "\n",
    "plt.xlabel(\"SNP\")\n",
    "plt.ylabel(\"lasso regression weight\")\n",
    "plt.xlim([0, p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: How can you interpret these results? How many SNPs contribute to explaining the phenotype?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%d SNPs selected\" % \\\n",
    "    np.nonzero(model_l1.best_estimator_.coef_)[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ Only 167 SNPs have been estimated to have non-zero weights. This means that our model selects 167 explanatory SNPs (out of 9419!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: How many of theses SNPS belong to the list of *candidate SNPs*? Complete the two missing lines two to compute the number of genes hit that belong to candidate genes and the number of snps that these genes correpond to.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "candidate_genes_hit = set([])\n",
    "num_snps_in_candidate_genes = 0\n",
    "for snp_idx in np.nonzero(model_l1.best_estimator_.coef_)[0]:\n",
    "    for gene_id in genes_by_snp[snp_names[snp_idx]]:\n",
    "        if gene_id in candidate_genes:\n",
    "            candidate_genes_hit.add(gene_id)\n",
    "            num_snps_in_candidate_genes += 1\n",
    "\n",
    "\n",
    "print(\"Of which %d are in %d candidate genes\" % (num_snps_in_candidate_genes, \n",
    "                                                          len(candidate_genes_hit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ Out of the 167 selected SNPs, 176 SNPs (counted with multiplicity) are \"close\" to candidate genes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive power "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2W_l1_pred = model_l1.best_estimator_.predict(X_2W_te)\n",
    "\n",
    "print(\"Percentage of variance explained (using %d SNPs): %.2f\" % \\\n",
    "     (np.nonzero(model_l1.best_estimator_.coef_)[0].shape[0], \n",
    "      metrics.explained_variance_score(y_2W_te, y_2W_l1_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: How does the lasso compare with the OLS (linear regression) in terms of variance explained? What is the advantage of the lasso model for generating biological hypotheses?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ Compared to unpenalized linear regression (also called OLS), the lasso has a similar variance explained, while using way fewer SNPs. So it is a better model: we need fewer mutations to explain the phenotype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing true and predicted phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5, 5))\n",
    "plt.scatter(y_2W_te, y_2W_l1_pred)\n",
    "\n",
    "plt.xlabel(\"true phenotype\")\n",
    "plt.ylabel(\"prediction\")\n",
    "plt.xlim([np.min(y_2W_te) - 0.05, np.max(y_2W_te) + 0.05])\n",
    "plt.ylim([np.min(y_2W_te) - 0.05, np.max(y_2W_te) + 0.05])\n",
    "plt.axline(xy1 = [0, 0], slope = 1, c = \"black\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlgen)",
   "language": "python",
   "name": "mlgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
